{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all xlsx files in the target directory and subdirectories\n",
    "def list_files(target_dir):\n",
    "    files = []\n",
    "    for root, dirs, filenames in os.walk(os.path.join(\".\", target_dir)):\n",
    "        for filename in filenames:\n",
    "            if filename.endswith(\".xlsx\"):\n",
    "                files.append(os.path.join(root, filename))\n",
    "    return files\n",
    "\n",
    "# Merge all files returned by list_files(target_dir) in a single dataframe\n",
    "def merge_files(target_dir):\n",
    "    import pandas as pd\n",
    "    files = list_files(target_dir)\n",
    "    df = pd.DataFrame()\n",
    "    for file in files:\n",
    "        df = pd.concat([df, pd.read_excel(file, engine=\"openpyxl\")], ignore_index=True)\n",
    "    return df\n",
    "\n",
    "# Merge all files and save the result in a single dataframe\n",
    "df_experiments = merge_files(\"new_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the column names in df_experiments\n",
    "print(df_experiments.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For rows having runtime_model as NaN, set runtime_model to 'NONE'\n",
    "df_experiments[\"runtime_model\"].fillna(\"NONE\", inplace=True)\n",
    "# For rows having runtime_model as BBB set CCC\n",
    "df_experiments[\"runtime_model\"] = df_experiments[\"runtime_model\"].replace(\"SafetyEnforcerKeepRight.asm\", \"KeepRight\")\n",
    "df_experiments[\"runtime_model\"] = df_experiments[\"runtime_model\"].replace(\"SafetyEnforcerFaster.asm\", \"Faster\")\n",
    "df_experiments[\"runtime_model\"] = df_experiments[\"runtime_model\"].replace(\"SafetyEnforcerSlower.asm\", \"Slower\")\n",
    "df_experiments[\"runtime_model\"] = df_experiments[\"runtime_model\"].replace(\"SafetyEnforcerSuperSafe.asm\", \"SuperSafe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter only rows with laneconfigurations as '1' and '2'\n",
    "df_experiments_multi = df_experiments[df_experiments['lane_configuration'].eq(\"multi\")]\n",
    "df_experiments_single = df_experiments[df_experiments['lane_configuration'].eq(\"single\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add columns for the relative number of enforer interventions and total enforcement overhead\n",
    "df_experiments['enforcement_interventions [%]'] = 100 * df_experiments['enforcer_interventions [#]'] / (df_experiments['policy_frequency [Hz]'] * df_experiments['effective_duration [s simulation time]'])\n",
    "df_experiments['enforcement_overhead [ms clock wall time]'] = df_experiments['enforcer_model_start [ms clock wall time]'] + df_experiments['enforcer_model_stop [ms clock wall time]'] + df_experiments['total_enforcement_execution_time [ms clock wall time]']\n",
    "\n",
    "# Define the grouping columns\n",
    "group_cols = ['policy_frequency [Hz]', 'lane_configuration', 'policy', 'runtime_model']\n",
    "\n",
    "# Define the aggregation functions for each column that must be in the aggregate dataframe\n",
    "agg_funcs = {\n",
    "    'crash [True/False]': 'sum',\n",
    "    'traveled_distance [km]': ['mean', 'std'], \n",
    "    'traveled_distance_on_right_lane [km]': ['mean', 'std'], \n",
    "    'enforcement_interventions [%]': ['mean', 'std'],\n",
    "    'test_execution_time [ms clock wall time]': ['mean', 'std'], \n",
    "    'enforcement_overhead [ms clock wall time]': ['mean', 'std']\n",
    "}\n",
    "\n",
    "# Perform the aggregation\n",
    "df_aggregated = df_experiments.groupby(group_cols).agg(agg_funcs)\n",
    "\n",
    "# Flatten the multi-index columns\n",
    "df_aggregated.columns = ['_'.join(col).strip() for col in df_aggregated.columns.values]\n",
    "\n",
    "# Reset index to make it a normal dataframe\n",
    "df_aggregated = df_aggregated.reset_index()\n",
    "\n",
    "# Convert all time-related columns from milliseconds to seconds\n",
    "time_columns = [\n",
    "    'test_execution_time [ms clock wall time]_mean',\n",
    "    'test_execution_time [ms clock wall time]_std',\n",
    "    'enforcement_overhead [ms clock wall time]_mean',\n",
    "    'enforcement_overhead [ms clock wall time]_std'\n",
    "]\n",
    "df_aggregated[time_columns] = df_aggregated[time_columns] / 1000\n",
    "\n",
    "# Define the custom order for sorting\n",
    "custom_order = {\n",
    "    'policy_frequency [Hz]': [1, 2],\n",
    "    'lane_configuration': ['single', 'multi'],\n",
    "    'policy': ['base', 'adversarial'],\n",
    "    'runtime_model': ['NONE', 'SuperSafe', 'Slower', 'Faster', \"KeepRight\"]\n",
    "}\n",
    "\n",
    "# Convert the columns to categorical with the specified order\n",
    "for col, order in custom_order.items():\n",
    "    df_aggregated[col] = pd.Categorical(df_aggregated[col], categories=order, ordered=True)\n",
    "\n",
    "# Sort the dataframe based on the custom order\n",
    "df_aggregated = df_aggregated.sort_values(by=group_cols)\n",
    "\n",
    "# Save the resulting dataframe to xlsx\n",
    "df_aggregated.to_excel(\"aggregated_results.xlsx\", index=False, float_format=\"%.2f\", engine='openpyxl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 8x5\n",
    "plt.figure(figsize=(3,4))\n",
    "sns.boxplot(x='runtime_model', y='traveled_distance [km]', data=df_experiments_multi, hue='policy_frequency [Hz]', showfliers=False, showmeans=True, order = ['NONE', 'KeepRight'])\n",
    "plt.legend(title='Policy frequency [Hz]', loc='best')\n",
    "# Values on the x-axis should be in the following order NONE, KeepRight\n",
    "plt.ylabel('Traveled distance [km]')\n",
    "plt.xticks(rotation=0)\n",
    "plt.xlabel('Enforcement model')\n",
    "plt.tight_layout()\n",
    "# Save the figure \n",
    "plt.savefig('figures/traveled_distance_multi.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4,4))\n",
    "sns.boxplot(x='runtime_model', y='traveled_distance [km]', data=df_experiments_single, hue='policy_frequency [Hz]', showfliers=False, showmeans=True, order = ['NONE', 'SuperSafe', 'Slower', 'Faster'])\n",
    "plt.legend(title='Policy frequency [Hz]', loc='best')\n",
    "plt.ylabel('Traveled distance [km]')\n",
    "plt.xticks(rotation=0)\n",
    "plt.xlabel('Enforcement model')\n",
    "plt.tight_layout()\n",
    "# Save the figure \n",
    "plt.savefig('figures/traveled_distance_single.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the DataFrame where 'crash [True/False]' is True\n",
    "crash_df = df_experiments[df_experiments['crash [True/False]'] == True]\n",
    "\n",
    "# Count occurrences of crashes for each runtime model\n",
    "crash_counts = crash_df['runtime_model'].value_counts()\n",
    "\n",
    "# Report on a histogram the number of crashes per runtime model. We count an execution as a crash if 'crash [True/False]' is True. Transpose the plot\n",
    "plt.figure(figsize=(2.1,4))\n",
    "sns.barplot(x=crash_counts.index, y=crash_counts.values)\n",
    "plt.ylabel('Number of crashes')\n",
    "plt.xticks(rotation=0)\n",
    "plt.xlabel('Enforcement model')\n",
    "plt.tight_layout()\n",
    "# Save the figure \n",
    "plt.savefig('figures/crashes.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
